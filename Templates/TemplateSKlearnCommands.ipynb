{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure()\n",
    "    train_sizes,train_scores,test_scores = learning_curve(estimator,X,y,cv=None,n_jobs=-1,train_sizes=train_sizes)\n",
    "    train_scores_mean= np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std  = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(\"on\") \n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "def print_result(estimator, n, X1, y1, X2, y2):\n",
    "\n",
    "    acc_scrs = cross_val_score(estimator, X1, y1, cv=StratifiedKFold(y1, n_folds=n), n_jobs=-1)\n",
    "    auc_scrs = cross_val_score(estimator, X1, y1, cv=StratifiedKFold(y1, n_folds=n), n_jobs=-1, scoring=\"roc_auc\")\n",
    "\n",
    "    print(\"Accuracy on Train: %0.5f (+/- %0.5f)\" %(np.mean(acc_scrs),np.std(acc_scrs)))\n",
    "    print(\" ROC_AUC on Train: %0.5f (+/- %0.5f)\" %(np.mean(auc_scrs),np.std(auc_scrs)))\n",
    "\n",
    "    estimator_fitted = estimator.fit(X1, y1)\n",
    "    y_scr = estimator_fitted.predict(X2)\n",
    "\n",
    "    print\n",
    "    print \"Confusion Matrix on Test:\"\n",
    "    print confusion_matrix(y2, y_scr)\n",
    "    print\n",
    "    print \"Classification Report on Test:\"\n",
    "    print classification_report(y2, y_scr)\n",
    "    print \"ROC_AUC on Test: %0.5f\" %(roc_auc_score(y2, y_scr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_trn = pd.read_csv(\"train.csv\")\n",
    "#df_tst = pd.read_csv(\"test.csv\")\n",
    "\n",
    "#trn_X = df_trn.loc[:,\"coli\":\"colj\"].drop_duplicates()\n",
    "#trn_ix = trn_X.index\n",
    "#df_trn = df_trn.ix[trn_ix]\n",
    "\n",
    "#(r, c)= df_trn.shape\n",
    "#index = pd.Index(range(r))\n",
    "#df_trn= df_trn.set_index(index)\n",
    "\n",
    "#cs_l = []\n",
    "#for i in range(r):\n",
    "#    cs_l.append(\"Train\")\n",
    "\n",
    "#cs_a = np.asarray(cs_l)\n",
    "#cs_s = pd.DataFrame(cs_a, columns=[\"Case\"], dtype=\"object\")\n",
    "#df_trn = pd.concat([cs_s, df_trn], axis=1)\n",
    "\n",
    "#y = df_trn[\"TARGET\"].values\n",
    "#df_trn.drop(\"TARGET\", axis=1, inplace=True)\n",
    "\n",
    "#(r, c) = df_tst.shape\n",
    "#cs_l = []\n",
    "#for i in range(r):\n",
    "#    cs_l.append(\"Test\")\n",
    "\n",
    "#cs_a = np.asarray(cs_l)\n",
    "#cs_s = pd.DataFrame(cs_a, columns=[\"Case\"], dtype=\"object\")\n",
    "#df_tst = pd.concat([cs_s, df_tst], axis=1)\n",
    "\n",
    "#df = pd.concat([df_trn, df_tst], axis=0) # top/bottom\n",
    "\n",
    "#(r, c)= df.shape\n",
    "#index = pd.Index(range(r))\n",
    "#df = df.set_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.info()\n",
    "#df.head(n=3)\n",
    "#df.describe()\n",
    "#df.axes\n",
    "#df.dtypes\n",
    "#df.empty\n",
    "#df.ndim\n",
    "#(r,c) = df.shape\n",
    "#df.values[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate and NaN check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if(len(df) == len(df.drop_duplicates())):\n",
    "#    print \"There is no dublicated rows\"\n",
    "#else:\n",
    "#    print \"There is dublicated rows !!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "#df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the \"object\" to \"integer\" dtype  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting the columns with \"object\" to \"category\" dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#objcols = df.select_dtypes([\"object\"]).columns\n",
    "#for i in range(len(objcols)):\n",
    "#    df[objcols[i]] = df[objcols[i]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting the columns with \"category\" to \"integer\" dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#catcols = df.select_dtypes([\"category\"]).columns\n",
    "#df[catcols] = df[catcols].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the high correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corr_mat = df.corr()\n",
    "\n",
    "#col_names = df.columns\n",
    "#ncol = len(col_names)\n",
    "#null_cols = []\n",
    "\n",
    "#for i in range(ncol-1):\n",
    "#    for j in range(i+1, ncol):\n",
    "#        if (abs(corr_mat.ix[i,j]) > 0.70):\n",
    "#            null_cols.append(col_names[j])\n",
    "\n",
    "#unique_cols = np.unique(null_cols)\n",
    "#df.drop(unique_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(df, kind=\"scatter\", diag_kind='hist')\n",
    "#plt.show()\n",
    "\n",
    "## kind: 'scatter', 'reg'\n",
    "## diag_kind: 'hist', 'kde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16, 12))\n",
    "#sns.corrplot(df.ix[:,1:])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "\n",
    "#df_X = df.loc[:, 'col1':'col2']\n",
    "#ar_Xs = preprocessing.scale(df_X.values)\n",
    "#df_Xs = pd.DataFrame(ar_Xs, columns=list(df_X.columns))\n",
    "\n",
    "#dfs = df\n",
    "#dfs.ix[:, 'col1':'col2'] = df_Xs\n",
    "\n",
    "#dfs_trn = dfs[dfs[\"Case\"]==\"Train\"]\n",
    "#dfs_tst = dfs[dfs[\"Case\"]==\"Test\"]\n",
    "\n",
    "#ar_trn_Xs = dfs_trn.loc[:, 'col1':'col2'].values\n",
    "#ar_tst_Xs = dfs_tst.loc[:, 'col1':'col2'].values\n",
    "\n",
    "#df_trn_Xs = pd.DataFrame(ar_trn_Xs, columns=list(df_X.columns))\n",
    "#df_tst_Xs = pd.DataFrame(ar_tst_Xs, columns=list(df_X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: SelectFpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectFpr\n",
    "\n",
    "#slct = SelectFpr(alpha = 1e-3)\n",
    "#slct_trn = slct.fit_transform(df_trn_Xs, y)\n",
    "\n",
    "#print (slct_trn.shape)\n",
    "\n",
    "#cols2stay = slct.get_support(indices = True)\n",
    "#columns = df_trn_Xs.columns\n",
    "\n",
    "#cols2rm = []\n",
    "#for i in range(len(columns)):\n",
    "#    if (i not in cols2stay):\n",
    "#        cols2rm.append(columns[i])\n",
    "\n",
    "#X = df_trn_Xs.drop(cols2rm, axis=1).values\n",
    "#X_val = df_tst_Xs.drop(cols2rm, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#sfm = SelectFromModel(clf, threshold=0.25)\n",
    "#slct_trn = sfm.fit_transform(df_trn_Xs, y)\n",
    "\n",
    "#print (slct_trn.shape)\n",
    "\n",
    "#cols2stay = slct.get_support(indices = True)\n",
    "#columns = df_trn_Xs.columns\n",
    "\n",
    "#cols2rm = []\n",
    "#for i in range(len(columns)):\n",
    "#    if (i not in cols2stay):\n",
    "#        cols2rm.append(columns[i])\n",
    "\n",
    "#X = df_trn_Xs.drop(cols2rm, axis=1).values\n",
    "#X_val = df_tst_Xs.drop(cols2rm, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data to the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Simple ML  Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.svm import LinearSVC                   # Support Vector Machines without kernels based on liblinear\n",
    "#from sklearn.linear_model import LogisticRegression # Regularized Logistic Regression based on liblinear\n",
    "#from sklearn.linear_model import SGDClassifier      # Regularized linear models (SVM or logistic regression) using\n",
    "                                                     # a Stochastic Gradient Descent algorithm written in Cython\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsClassifier  # k-Nearest Neighbors classifier based on the ball tree\n",
    "                                                     # datastructure for low dimensional data and brute force\n",
    "                                                     # search for high dimensional data.\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB          # Gaussian Naive Bayes model. This is an unsophisticated\n",
    "                                                     # model which can be trained very quickly. It is often used\n",
    "                                                     # to obtain baseline results before moving to a more\n",
    "                                                     # sophisticated classifier.\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier     # A classifier based on a series of binary decisions. This is\n",
    "                                                     # another very fast classifier, which can be very powerful.\n",
    "#clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.1. Plotting the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_learning_curve(clf,\"accuracy vs. training set size\", X_train, \n",
    "#                                                          y_train,\n",
    "#                                                           cv = 5,\n",
    "#                                                  train_sizes = np.linspace(0.1,1.0,9))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_result(clf, 5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More Complex ML Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. Making a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "# with pipeline, we can put together quncequen functions to make a classifier as below, \n",
    "# clf_pipeline = Pipeline([('name 1', function 1), ('name 2', function 2), ('clf_nm', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Making GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "#Cs = (np.linspace(1, 100, num=4)).tolist()\n",
    "#gammas = np.linspace(0.0001, 0.001, num = 3).tolist()\n",
    "\n",
    "#clf_param_grid = [{'clf__C': Cs, 'clf__kernel': ['linear']},\n",
    "#                  {'clf__C': Cs, 'clf__kernel': ['rbf'], 'clf__gamma': gammas}]\n",
    "\n",
    "#clf_grid = GridSearchCV(clf_pipeline,\n",
    "#           param_grid = clf_param_grid,\n",
    "#                refit = True,\n",
    "#               n_jobs = -1,\n",
    "#              scoring = 'accuracy',\n",
    "#                   cv = StratifiedKFold(y_train, n_folds=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. Training the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf_label_detector = clf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(len(clf_label_detector.grid_scores_)):\n",
    "#    print clf_label_detector.grid_scores_[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4. Aplying to the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print confusion_matrix(y_test, clf_label_detector.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print classification_report(y_test, clf_label_detector.predict(X_test)).splitlines()[0]\n",
    "#print classification_report(y_test, clf_label_detector.predict(X_test)).splitlines()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5. Saving the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "#with open(\"ClasifierName.pkl\", \"wb\") as fout:\n",
    "#    pickle.dump(clf_final_detector, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6. Loading the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ClasifierName_loaded = pickle.load(open(\"ClasifierName.pkl\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
